{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used for displaying plots below the cell\n",
    "%matplotlib inline\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_df = pd.read_csv('customer_features.csv', sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization  \n",
    "Z-scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(cust_df.values)\n",
    "X = scaler.transform(cust_df.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the Knee method to find the best k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse_list = list()\n",
    "max_k = 40\n",
    "for k in range(2, max_k + 1): #Starting from k=2 to k=40\n",
    "    kmeans = KMeans(n_clusters=k, n_init=10, max_iter=100)\n",
    "    kmeans.fit(X)\n",
    "    \n",
    "    sse = kmeans.inertia_\n",
    "    sse_list.append(sse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(2, len(sse_list) + 2), sse_list)\n",
    "plt.ylabel('SSE', fontsize=18)\n",
    "plt.xlabel('K', fontsize=18)\n",
    "plt.tick_params(axis='both', which='major', labelsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that around K=10 Â± 5 we get diminishing returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=10, n_init=10, max_iter=100)\n",
    "kmeans.fit(X)\n",
    "centers = scaler.inverse_transform(kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist, bins = np.histogram(kmeans.labels_, \n",
    "                          bins=range(0, len(set(kmeans.labels_)) + 1))\n",
    "dict(zip(bins, hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(cust_df, c=kmeans.labels_, figsize=(20,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 5))\n",
    "for i in range(0, len(centers)):\n",
    "    plt.plot(centers[i], marker='o', label='Cluster %s' % i)\n",
    "plt.tick_params(axis='both', which='major', labelsize=18)\n",
    "plt.xticks(range(0, len(cust_df.columns)), cust_df.columns, fontsize=18)\n",
    "plt.legend(fontsize=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of variable\n",
    "N = len(cust_df.columns)\n",
    "# What will be the angle of each axis in the plot? (we divide the plot / number of variable)\n",
    "\n",
    "# Initialise the spider plot\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax = plt.subplot(polar=True)\n",
    "\n",
    "for i in range(0, len(centers)):\n",
    "    angles = [n / float(N) * 2 * math.pi for n in range(N)]\n",
    "    values = centers[i].tolist()\n",
    "    values += values[:1]\n",
    "    angles += angles[:1]\n",
    "    \n",
    "# Draw one axe per variable + add labels labels yet\n",
    "    plt.xticks(angles[:-1], cust_df.columns, color='grey', size=8) \n",
    "# Plot data\n",
    "    ax.plot(angles, values, linewidth=1, linestyle='solid')\n",
    " # Fill area\n",
    "    ax.fill(angles, values, 'b', alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X) #We need the normalised data\n",
    "print(pca.explained_variance_ratio_) #Variance explained by the components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are retaining approximately 86% of the variance.  \n",
    "Let's apply the elbow method to the PCA transformed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse_list = list()\n",
    "max_k = 40\n",
    "for k in range(2, max_k + 1): #Starting from k=2 to k=40\n",
    "    kmeans = KMeans(n_clusters=k, n_init=10, max_iter=100)\n",
    "    kmeans.fit(X_pca)\n",
    "    \n",
    "    sse = kmeans.inertia_\n",
    "    sse_list.append(sse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(2, len(sse_list) + 2), sse_list)\n",
    "plt.ylabel('SSE', fontsize=22)\n",
    "plt.xlabel('K', fontsize=22)\n",
    "plt.tick_params(axis='both', which='major', labelsize=22)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal value is still k=10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_kmeans = KMeans(n_clusters=10, n_init=10, max_iter=100)\n",
    "pca_kmeans.fit(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=pca_kmeans.labels_, edgecolor='k', s=40)\n",
    "plt.title(\"PCA\")\n",
    "plt.xlabel(\"1st eigenvector\")\n",
    "plt.ylabel(\"2nd eigenvector\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clusters are well separated.  \n",
    "We now have a new categorical feature to help us analyse the pre-PCA dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

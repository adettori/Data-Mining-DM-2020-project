{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used for displaying plots below the cell\n",
    "%matplotlib inline\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "from scipy.stats.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('customer_supermarket.csv', sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset seems to contain data about the shopping habits of the customers of a grocery store chain.  \n",
    "Each row represents an object purchased:  \n",
    "- BasketID: represents a batch of items bought during the same shopping session  \n",
    "- BasketDate: date in which the shopping session took place  \n",
    "- Sale: represents the value of the item, we need to figure out if it refers to a single item or the item*quantity\n",
    "- CustomerID: identifies a unique customer\n",
    "- ProdID: identifies a unique product for sale\n",
    "- ProdDescr: describes the product\n",
    "- Qta: number of items of the with id ProdID bought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only ProdDescr and CustomerID contain null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The statistics regarding the CustomerID are meaningless since the assignment of an ID is usually done progressively and without having any additional information on the customer.  \n",
    "We need to fix the data type situation in order to get a better understanding of the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data type conversion  \n",
    "Let's start by checking out the data type that pandas assigns to the attributes, in order to get an idea of the potential problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CustomerID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CustomerID got converted to a reasonable data type while the others became a generic \"string\".  \n",
    "We don't however care for CustomerID as a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"CustomerID\"] = df[\"CustomerID\"].astype(\"string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BasketDate\n",
    "Let's convert the BasketDate type from String to datetime, just in case we need to perform some analysis that requires ordinal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.BasketDate = pd.to_datetime(df.BasketDate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"Sale\" attribute is considered a generic object while it should be recognised as a float.  \n",
    "Let's see why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Sale.map(type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.Sale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that Sale uses a comma instead of a point to separate the decimal part, so it is considered a \"str\" instead of a \"float64\".  \n",
    "Let's replace the commas in \"Sale\" with dots in order to have them be recognised as float64 by pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Sale = df.Sale.apply(lambda x: x.replace(',','.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Sale = df.Sale.astype(\"float64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sale is now correctly identified as a float64."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration data frame\n",
    "Used for exploration purposes but not necessarily useful for clustering.  \n",
    "Initialised with some additional features that could prove useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auxiliary df to be used throughout the data understanding phase\n",
    "df_expl = df[[\"BasketID\", \"Qta\", \"Sale\"]].copy()\n",
    "\n",
    "df_expl[\"QtaPositive\"] = 0\n",
    "df_expl.loc[df_expl[\"Qta\"] > 0, \"QtaPositive\"] = 1 #Indicates whether the records Qta is positive\n",
    "\n",
    "df_expl[\"SalePositive\"] = 0\n",
    "df_expl.loc[df_expl[\"Sale\"] > 0, \"SalePositive\"] = 1 #Indicates whether the records Sale is positive\n",
    "\n",
    "df_expl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BasketID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check why BasketID is not considered an int64 like CustomerID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonNumSeries = pd.to_numeric(df.BasketID, errors='coerce').isnull()\n",
    "# Print the records with BasketIDs containing a non-numeric value\n",
    "df[nonNumSeries].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[nonNumSeries, \"BasketID\"].str.slice(0,1).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that a good chunk of the BasketID values start with a \"C\" and some with \"A\" instead of being just numbers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket_c_df = df.loc[df[\"BasketID\"].str.get(0) == \"C\"]\n",
    "len_basket_c = len(basket_c_df)\n",
    "print(f\"Records starting with 'C' (Size: {len_basket_c}):\\n\")\n",
    "basket_c_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basket_a_df = df.loc[df[\"BasketID\"].str.get(0) == \"A\"]\n",
    "len_basket_a = len(basket_a_df)\n",
    "print(f\"Records starting with 'A' (Size: {len_basket_a}):\\n\")\n",
    "basket_a_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be a strong correlation between the \"C\" and a negative quantity, this could indicate a customer that asked for a refund.  \n",
    "\n",
    "There is also some interesting correlation between the \"A\" start and a ProdDescr containing \"Adjust bad debt\", maybe the \"A\" stands for adjust and since the CustomerID in both cases is NaN this could be an operation that concerns only the management of the shop and not something that concerns the customers (which is our primary objective).  \n",
    "These records, however, are too few to be meaningful, they skew too much the characteristics of the sale data (outliers) and they don't concern the activities of the customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to add a \"BasketID type A\" and \"BasketID type C\" binary attribute (0/1) and see if there are correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialise all the cells to 0\n",
    "df_expl[\"BasketIDTypeA\"] = 0\n",
    "df_expl[\"BasketIDTypeC\"] = 0\n",
    "\n",
    "#Set the cells appropriately depending on the BasketID type\n",
    "df_expl.loc[df[\"BasketID\"].str.get(0) == \"A\", \"BasketIDTypeA\"] = 1\n",
    "df_expl.loc[df[\"BasketID\"].str.get(0) == \"C\", \"BasketIDTypeC\"] = 1\n",
    "\n",
    "df_expl[\"NewBasketID\"] = df_expl[\"BasketID\"]\n",
    "\n",
    "#Remove the initial letter from BasketID where necessary\n",
    "df_expl.loc[df_expl[\"BasketID\"].str.get(0) == \"A\", \"NewBasketID\"] = df_expl.loc[(df_expl[\"BasketID\"].str.get(0) == \"A\"), \"BasketID\"].str.slice(start=1)\n",
    "df_expl.loc[df_expl[\"BasketID\"].str.get(0) == \"C\", \"NewBasketID\"] = df_expl.loc[(df_expl[\"BasketID\"].str.get(0) == \"C\"), \"BasketID\"].str.slice(start=1)\n",
    "\n",
    "df_expl.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BasketID of type C has a strong negative correlation with the sign of Qta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"BasketID\"].str.get(0) == \"C\", \"ProdDescr\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What could this mean for the C type? Probably indicates discounts/refunds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expl[\"NewBasketID\"] = df_expl[\"NewBasketID\"].astype(\"int64\")\n",
    "df_expl.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that there are no more anomalies inside BasketID since it can be now converted to int64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expl[\"NewBasketID\"] = df_expl[\"NewBasketID\"].astype(\"string\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if we now have less unique BasketIDs in our records, after removing the type from the BasketID attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The original number of unique BasketIDs is: {df_expl[\"BasketID\"].unique().size}')\n",
    "print(f'The current number of unique BasketIDs is: {df_expl[\"NewBasketID\"].unique().size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number is the same, therefore each BasketID of type A or C didn't merge with pre-existing shopping sessions.  \n",
    "It could prove useful to take into account the BasketDate and see if it would make sense to merge the type C records with the ones in the same day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BasketDate\n",
    "Let's see how the entries are distributed over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonNullEntries = df[df[\"BasketID\"].notna()]\n",
    "k = math.ceil(math.log(len(nonNullEntries), 2) + 1) #Sturge's rule\n",
    "df[\"BasketDate\"].hist(bins=k, figsize=(10,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of transactions increases month by month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distributions of Sale and Qta taking into account the BasketDate\n",
    "fig = plt.figure(figsize=(20, 5)) \n",
    "fig_dims = (1, 2)\n",
    "fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "\n",
    "plt.subplot2grid(fig_dims, (0, 0))\n",
    "\n",
    "plt.scatter(df['BasketDate'], \n",
    "            df['Sale'], color='g', marker='*', label='Data')\n",
    "plt.xlabel('BasketDate')\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.ylabel('Sale')\n",
    "\n",
    "\n",
    "plt.subplot2grid(fig_dims, (0, 1))\n",
    "\n",
    "plt.scatter(df['BasketDate'], \n",
    "            df['Qta'], color='g', marker='*', label='Data')\n",
    "plt.xlabel('BasketDate')\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.ylabel('Qta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the number of shopping sessions per customer per day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by=[\"CustomerID\", \"BasketDate\"])[\"BasketID\"].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There doesn't seem to be a way to easily merge the type C BasketID records with other shopping sessions.  \n",
    "The discounts/refunds will be considered as separate orders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sale\n",
    "We need to figure out if the Sale value refers to the cost of a single item or cost of item * Qta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=\"ProdID\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that Sale doesn't change if the Qta is changed... let's verify it further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There doesn't seem to be a correlation in general between Sale and Qta, so they are indipendent variables(?) and therefore Sale is the cost of the signle item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the Sale distribution\n",
    "fig = plt.figure(figsize=(20, 10)) \n",
    "fig_dims = (1, 2)\n",
    "fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
    "\n",
    "plt.subplot2grid(fig_dims, (0, 0))\n",
    "k = math.ceil(math.log(len(df[\"Sale\"]), 2) + 1) #Sturge's rule\n",
    "df[\"Sale\"].hist(bins=k)\n",
    "\n",
    "plt.subplot2grid(fig_dims, (0, 1))\n",
    "df.boxplot(column=[\"Sale\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected the vast majority of Sale values is near 0, we need however to check for 0 values since they don't make sense in the contest of Sale and therefore should be considered as missing values.  \n",
    "Note also that the median is near the 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"Sale\"] == 0].size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost a quarter of the Sale values are 0, this needs to be fixed in the Data Preparation phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CustomerID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see why the number of non-null CustomerID entries is so low and if there are any interesting properties to be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expl[\"CustomerID\"] = df[\"CustomerID\"]\n",
    "\n",
    "df_expl[\"CustomerIDNull\"] = 0\n",
    "df_expl.loc[df_expl[\"CustomerID\"].isna(), \"CustomerIDNull\"] = 1\n",
    "\n",
    "df_expl.corr()[\"CustomerIDNull\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No interesting correlation.  \n",
    "Let's check if we can retrieve some missing CustomerIDs by using the records referencing the same BasketID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by=\"BasketID\").filter(lambda x: x[\"CustomerID\"].isna().any() & x[\"CustomerID\"].notna().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the code above didn't give any result there doesn't seem to be a way to easily fill-in the missing CustomerID values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"CustomerCountry\"].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of the operations take place in the United Kingdom.  \n",
    "It could be interesting to however take into account the revenue by country and see which is more profitable relative to the number of orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryList = df[\"CustomerCountry\"].sort_values().unique()\n",
    "country_df = pd.DataFrame(data=countryList, columns=[\"Country\"])\n",
    "\n",
    "df[\"ProductSaleQta\"] = df[\"Sale\"]*df[\"Qta\"]\n",
    "\n",
    "for country in countryList:\n",
    "    country_df.loc[country_df[\"Country\"] == country, \"TotalSale\"] = df.loc[df[\"CustomerCountry\"] == country, \"ProductSaleQta\"].sum()\n",
    "\n",
    "df = df.drop(\"ProductSaleQta\", axis=1)\n",
    "country_df.sort_values(by=\"TotalSale\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ProdID\n",
    "Let's find out why this wasn't converted to a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"ProdID\"].str.isnumeric(), (\"ProdID\", \"ProdDescr\")].value_counts() #Records with ProdIDs containing only numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"ProdID\"].str.isalpha(), (\"ProdID\", \"ProdDescr\")].value_counts() #Records with ProdIDs containing only letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Records with ProdID terminating with a letter\n",
    "term_letter_prodid = df.loc[(df[\"ProdID\"].str.slice(start=-1).str.isalpha()) & (df[\"ProdID\"].str.slice(0, -1).str.isnumeric())]\n",
    "term_letter_prodid.sort_values(by=\"ProdID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_letter_prodid[\"ProdID\"].str.slice(start=-1).sort_values().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the diversity and lack of structure of the ProdIDs there doesn't seem to be interesting information to obtain.  \n",
    "There doesn't even seem to be consistency between the descriptions and ProdIDs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = math.ceil(math.log(len(df[\"Qta\"]), 2) + 1) #Sturge's rule\n",
    "df[\"Qta\"].hist(bins=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check for 0 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"Qta\"] == 0].size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no records with Qta equal to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expl.corr()[\"QtaPositive\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted in the BasketID section there is a strong correlation between the sign of Qta and a BasketID of type C.  \n",
    "Let's see if there is something interesting distribution in the remaining negative quantities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "expl_result = df_expl.loc[(df_expl[\"Qta\"] < 0) & (df_expl[\"BasketIDTypeC\"] == 0)]\n",
    "expl_result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the trend of Sale equal 0 continues throughout the subset of records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl_result[\"Sale\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does.  \n",
    "Let's check if all CustomerIDs in the subset are Null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl_result.describe()[\"CustomerIDNull\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are all Null.  \n",
    "It might be a good idea to remove this data in the Data preparation phase.  \n",
    "This way we will also have a correlation of 1 between the BasketID class C and negative quantities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: fill in missing values of sale, remove outliers, remove records with neg Qta except class C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add some new features into the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unq_cust_id = df[\"CustomerID\"].sort_values().unique()[0:-1] #Remove NaN value, last value\n",
    "cust_df = pd.DataFrame(data=unq_cust_id, columns=[\"CustomerID\"]) #Dataframe containing customer features\n",
    "\n",
    "#Total number of items bought by customer\n",
    "IFeature = df.groupby([\"CustomerID\"]).Qta.sum()\n",
    "cust_df = cust_df.merge(IFeature, on=\"CustomerID\").rename(columns={\"Qta\":\"I\"})\n",
    "\n",
    "#Total number of unique items bought by customer\n",
    "IuFeature = df.groupby([\"CustomerID\"]).ProdID.nunique()\n",
    "cust_df = cust_df.join(IuFeature, on=\"CustomerID\").rename(columns={\"ProdID\":\"Iu\"})\n",
    "\n",
    "#Max number of item bought by customer across all shopping sessions\n",
    "BasketIDQtaSum= df.groupby([\"CustomerID\", \"BasketID\"]).Qta.sum()\n",
    "ImaxFeature = BasketIDQtaSum.groupby([\"CustomerID\"]).max()\n",
    "cust_df = cust_df.join(ImaxFeature, on=\"CustomerID\").rename(columns={\"Qta\":\"Imax\"})\n",
    "\n",
    "#The Shannon entropy on the purchasing behaviour of the customer (sum -p_items * log2(p_items))\n",
    "#Potential problem: p could be a negative value!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "cust_prod_tot = df.groupby([\"CustomerID\", \"ProdID\"]).Qta.sum()\n",
    "probSeries = (cust_prod_tot/IFeature).rename({\"Qta\":\"P_prod_customer\"})\n",
    "logSeries = np.log2(probSeries)\n",
    "entropy = -1*probSeries*logSeries\n",
    "EFeature = entropy.groupby([\"CustomerID\"]).sum()\n",
    "cust_df = cust_df.join(EFeature, on=\"CustomerID\").rename(columns={\"Qta\":\"E\"})\n",
    "\n",
    "cust_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting correlation between E and Iu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(cust_df['I'], \n",
    "            cust_df['Iu'], color='g', marker='*', label='Data')\n",
    "plt.xlabel('I')\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.ylabel('Iu')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
